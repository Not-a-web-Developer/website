<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title>mayukh_chr</title>
    <link rel="self" type="application/atom+xml" href="/atom.xml"/>
    <link rel="alternate" type="text/html" href="/"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2024-11-01T00:00:00+00:00</updated>
    <id>/atom.xml</id>
    <entry xml:lang="en">
        <title>My Experience with Building a Ray Tracer</title>
        <published>2024-11-01T00:00:00+00:00</published>
        <updated>2024-11-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/posts/my-experience-with-building-a-ray-tracer/"/>
        <id>/posts/my-experience-with-building-a-ray-tracer/</id>
        
        <content type="html" xml:base="/posts/my-experience-with-building-a-ray-tracer/">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;&#x2F;h1&gt;
&lt;p&gt;    Despite how my &lt;a href=&quot;http:&#x2F;&#x2F;github.com&#x2F;mayukh-chr&quot;&gt;GitHub contributions&lt;&#x2F;a&gt; might look, my preferred programming language is actually C++. I’ve used it extensively for Leetcode and Codeforces since learning it about a year ago. My reasons for choosing C++ are its convenient STL library, faster runtime (compared to Python), and relatively concise syntax (unlike Java and C), making it a top choice for competitive programmers. Naturally, after working with the fundamentals for so long, I decided to take on a project in C++.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;the-project&quot;&gt;The Project&lt;&#x2F;h1&gt;
&lt;p&gt;    I chose to work through the book &lt;a href=&quot;https:&#x2F;&#x2F;raytracing.github.io&#x2F;books&#x2F;RayTracingInOneWeekend.html&quot;&gt;&lt;em&gt;Ray Tracing in One Weekend&lt;&#x2F;em&gt;&lt;&#x2F;a&gt; by &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;petershirley&quot;&gt;Peter Shirley&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;trevordblack&quot;&gt;Trevor David Black&lt;&#x2F;a&gt;, and &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;trevordblack&quot;&gt;Steve Hollasch&lt;&#x2F;a&gt;. This book is the first in a trilogy, all available for free, and it includes code snippets that help when you get stuck. &lt;&#x2F;p&gt;
&lt;p&gt;    I wanted to work on something related to game engines, a domain I hadn’t yet explored. Since Nvidia’s 2018 RTX announcement, I’ve been intrigued by ray tracing and wanted to experiment with it. However, without access to the necessary GPUs, I had to leave RTX-specific experimentation aside for now.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;what-i-learned&quot;&gt;What I Learned&lt;&#x2F;h1&gt;
&lt;p&gt;    The book starts with generating a simple RGB image in PPM format and gradually introduces features like scenes, cameras, and objects. In the second half, it simulates light rays hitting the camera with effects like reflections, refractions, diffusion, anti-aliasing, and even lens blur.&lt;&#x2F;p&gt;
&lt;p&gt;$$ From \space this $$
&lt;img src=&quot;&#x2F;images&#x2F;p3&#x2F;img-1.03-red-sphere.png&quot; alt=&quot;img1&quot; &#x2F;&gt;
$$ to \space this $$
&lt;img src=&quot;&#x2F;images&#x2F;p3&#x2F;img-1.23-book1-final.jpg&quot; alt=&quot;img2&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;challenges-i-faced&quot;&gt;Challenges I Faced&lt;&#x2F;h2&gt;
&lt;p&gt;    My competitive programming experience in C++ was limited to using the STL, with little exposure to Object-Oriented Programming (OOP) concepts. This project was my first experience with OOP in C++, and I found it challenging. No matter how much OOP code I write, I can’t seem to fully get comfortable with it. Interestingly, I found my coursework in Java (which is more explicit in its syntax) to be a bit easier. I had to look up several terms I hadn’t encountered before, as some weren’t covered in my OOP classes.&lt;&#x2F;p&gt;
&lt;p&gt;    Additionally, I was working with many custom data types (e.g., vectors, points, surfaces, materials) for the first time, which took time to adjust to, as I was mostly familiar with predefined types.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;future-directions&quot;&gt;Future Directions&lt;&#x2F;h1&gt;
&lt;p&gt;    I skimmed through the next two parts of the book and, although I’m very interested in continuing the project, I feel I&#x27;ll end up with the same feelings after finishing it. I attempted to implement multithreading to speed up rendering, but I struggled with thread synchronization during rendering. I’d love to try implementing the project with &lt;a href=&quot;https:&#x2F;&#x2F;developer.nvidia.com&#x2F;blog&#x2F;accelerated-ray-tracing-cuda&#x2F;&quot;&gt;CUDA&lt;&#x2F;a&gt; someday when I have access to the necessary hardware.&lt;&#x2F;p&gt;
&lt;p&gt;    I do want to work in low level systems with C++ (or even rust), because in my opinion that&#x27;s a domain it has a slow developmental cycle a lot of memory sensitive procedures, making sure the end product is as tight as possible in terms of response times and memory handling. &lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>How Do Computers Learn?</title>
        <published>2024-07-29T00:00:00+00:00</published>
        <updated>2024-07-29T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/posts/how-do-computers-learn/"/>
        <id>/posts/how-do-computers-learn/</id>
        
        <content type="html" xml:base="/posts/how-do-computers-learn/">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;&#x2F;h1&gt;
&lt;p&gt;    At the beginning of this year, a technical club at my university hosted a &amp;quot;Build an AI&#x2F;ML model&amp;quot; workshop aimed towards teaching freshers how to get started with AI. The workshop involved building a digit classification model that recognised handwritten digits using TensorFlow on Jupyter notebooks. Although it was a great beginners tutorial on TensorFlow, I felt dissatisfied with that because it didn&#x27;t explain how the model actually &amp;quot;learnt&amp;quot;, improving its weights and reducing the loss function.&lt;&#x2F;p&gt;
&lt;p&gt;    As much I&#x27;d like to go into detail about every part of the code line by line like my previous blog, it would be simply too cumbersome for my liking as a.) The code is relatively bigger, and b.) I find the mathematics behind it more fascinating. Additionally, I would highly suggest reading &lt;a href=&quot;http:&#x2F;&#x2F;neuralnetworksanddeeplearning.com&#x2F;&quot;&gt;this textbook&lt;&#x2F;a&gt; by Michael Nielsen to have a more thorough understanding.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;neurons&quot;&gt;Neurons&lt;&#x2F;h1&gt;
&lt;p&gt;The foundation of any neural network, whether biological or artificial, lies in its basic building blocks: neurons. In the human brain, neurons are specialized cells that transmit information through electrical and chemical signals. They form complex networks that enable us to think, learn, and perform various cognitive tasks. Similarly, in the realm of artificial intelligence, neurons are the computational units that process and transmit data within a network, enabling the system to learn and make decisions.&lt;&#x2F;p&gt;
&lt;p&gt;    When we talk about artificial neurons, we&#x27;re referring to mathematical functions that receive one or more inputs, process them, and produce an output. These artificial neurons are designed to mimic the behavior of their biological counterparts, albeit in a much simpler and more abstract form. &lt;&#x2F;p&gt;
&lt;h2 id=&quot;perceptron&quot;&gt;Perceptron&lt;&#x2F;h2&gt;
&lt;p&gt;    Similar to the neurons in your brain, computer neurons re-emit signals recieved from other sources.
Perhaps the simplest form of a computer neuron would be a &lt;a href=&quot;https:&#x2F;&#x2F;books.google.ca&#x2F;books&#x2F;about&#x2F;Principles_of_neurodynamics.html?id=7FhRAAAAMAAJ&amp;amp;hl=en&quot;&gt;perceptron&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;p2&#x2F;perceptron.png&quot; alt=&quot;perceptron&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;A perceptron takes in one or more binary inputs (0&#x2F;1) and outputs one binary value. It is calculated by&lt;&#x2F;p&gt;
&lt;p&gt;$$
output =
\begin{cases}
0 &amp;amp; \text{if } \sum_j w_j x_j \leq \text{threshold} \newline
1 &amp;amp; \text{if } \sum_j w_j x_j &amp;gt; \text{threshold}
\end{cases}
\tag{1}
$$&lt;&#x2F;p&gt;
&lt;p&gt;or converting $\sum_j w_j x_j$ to its dot product forms $w \cdot x$ and re-defining the threshold as the convention, bias $b$, we can rewrite it as&lt;&#x2F;p&gt;
&lt;p&gt;$$
output =
\begin{cases}
0 &amp;amp; \text{if } w \cdot x - b \leq 0 \newline
1 &amp;amp; \text{if } w \cdot x - b &amp;gt; 0
\end{cases}
\tag{2}
$$&lt;&#x2F;p&gt;
&lt;p&gt;That&#x27;s the basic mathematical model. It says yes or no depending on how the inputs are formed, A simple example would be: imagine your friends call you for a weekend getaway at the beach. Your decision to go depends on three factors:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Is your boyfriend&#x2F;girlfriend joining?&lt;&#x2F;li&gt;
&lt;li&gt;Is it going to rain?&lt;&#x2F;li&gt;
&lt;li&gt;Are you going by car?\end&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;ul&gt;
&lt;li&gt;You place option 1 as the most important, and weigh that in at $w_1 = 3$&lt;&#x2F;li&gt;
&lt;li&gt;You weigh in option 2 at $w_2  = 2$ and &lt;&#x2F;li&gt;
&lt;li&gt;$w_3 = 1$&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;$x_i$ basically means &amp;quot;is option $i$ true or not, if it is $x_i = 1$ else its $0$.
Assuming a bias $b = 5$. &lt;&#x2F;p&gt;
&lt;p&gt;if option 1, 3 are true and 2 is false:&lt;&#x2F;p&gt;
&lt;p&gt;$$w \cdot x - b = (3×1)+(2×0)+(1×1)= -1 &amp;lt; 0$$ so you don&#x27;t go
but if all 3 are true:&lt;&#x2F;p&gt;
&lt;p&gt;$$w\cdot x−b=(3×1)+(2×1)+(1×1)−5=3+2+1−5=1&amp;gt;0$$&lt;&#x2F;p&gt;
&lt;p&gt;So, you decide to go.&lt;&#x2F;p&gt;
&lt;p&gt;    This example illustrates how a perceptron can make simple decisions based on weighted inputs and a bias. Each weight represents the importance of a corresponding input, and the bias adjusts the threshold for decision-making. By adjusting the weights and bias, a perceptron can be trained to perform various logical operations and make decisions based on input data.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;sigmoid-neuron&quot;&gt;Sigmoid Neuron&lt;&#x2F;h2&gt;
&lt;p&gt;    To see how learning might work, suppose we make a small change in some weight (or bias) in the network. What we&#x27;d like is for this small change in weight to cause only a small corresponding change in the output from the network. Schematically, here&#x27;s what we want (sort of):&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;p2&#x2F;learning.png&quot; alt=&quot;learning&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;If a small change in a weight (or bias) causes a small change in the output, we can adjust the weights and biases to improve the network&#x27;s performance. For example, if the network incorrectly classifies an image as an &amp;quot;8&amp;quot; instead of a &amp;quot;9&amp;quot;, we can slightly change the weights and biases to make the network more likely to classify the image as a &amp;quot;9&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;    Unfortunately for our perceptrons, a small change in the weights or bias of one of them in the network can sometimes switch the output of the perceptron from 1 to 0 and vice versa. That flip may then cause the behaviour of the rest of the network to completely change in some very complicated way. So while your &amp;quot;9&amp;quot; might now be classified correctly, the behaviour of the network on all the other images is likely to have completely changed in some hard-to-control way.&lt;&#x2F;p&gt;
&lt;p&gt;The solution to this was a new, but similar type of neuron called the sigmoid neuron. Which works with this logic:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;p2&#x2F;sigmoid1.png&quot; alt=&quot;sigmoid neuron&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;It looks the same as the perceptrons that we saw earlier. Altho it has a few changes:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Instead of the inputs being 0 or 1, these inputs can take on any value between 0 and 1, eg: 0.532... could be one input.&lt;&#x2F;li&gt;
&lt;li&gt;Just like a perceptron, it has weights for each input $w1, w2...$ and bias b. But the output is not 0 or 1. Its $\sigma(w \cdot x + b)$ where the &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sigmoid_function&quot;&gt;sigma function&lt;&#x2F;a&gt; (also called the logistic function) is:&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;$$ \sigma(z) = \frac{1}{1 + e^{-z}} \tag{3}$$&lt;&#x2F;p&gt;
&lt;p&gt;    At first it looks a lot more complicated than the perceptron but suppose $z≡w⋅x+b$ is a large positive number. Then $e−z≈0$ and so $σ(z)≈1$. In other words, when $z=w⋅x+b$ is large and positive, the output from the sigmoid neuron is approximately 1, just as it would have been for a perceptron. Suppose on the other hand that $z=w⋅x+b$ is very negative. Then $e−z→∞$, and $σ(z)≈0$. So when z=w⋅x+b is very negative, the behaviour of a sigmoid neuron also closely approximates a perceptron.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;p2&#x2F;sigmoid-graph.png&quot; alt=&quot;sigmoid function graph&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;So basically a sigma function is a smoother version of the step function. Which allows us to make slight changes in $w$ and $b$ for slight change in the output. As approximated by:&lt;&#x2F;p&gt;
&lt;p&gt;$$
\Delta \text{output} \approx \sum_j \frac{\partial \text{output}}{\partial w_j} \Delta w_j + \frac{\partial \text{output}}{\partial b} \Delta b
\tag{4}
$$&lt;&#x2F;p&gt;
&lt;p&gt;    This can be useful, for example, if we want to use the output value to represent the average intensity of the pixels in an image input to a neural network. But sometimes it can be a nuisance. Suppose we want the output from the network to indicate either &amp;quot;the input image is a 9&amp;quot; or &amp;quot;the input image is not a 9&amp;quot;. Obviously, it&#x27;d be easiest to do this if the output was a 0 or a 1, as in a perceptron. But in practice we can set up a convention to deal with this, for example, by deciding to interpret any output of at least 0.5 as indicating a &amp;quot;9&amp;quot;, and any output less than 0.5 as indicating &amp;quot;not a 9&amp;quot;.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;the-architecture-of-neural-networks&quot;&gt;The architecture of neural networks&lt;&#x2F;h1&gt;
&lt;p&gt;Suppose we have the network:&lt;&#x2F;p&gt;
&lt;!-- ![architecture](&#x2F;images&#x2F;p2&#x2F;architecture.png) --&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;p2&#x2F;architecture2.png&quot; alt=&quot;architecture&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The leftmost layer in this network is called the input layer, and the neurons within the layer are called input neurons. The rightmost or output layer contains the output neurons, or, as in this case, a single output neuron. The 2 middle layers are called hidden layers, called because the neurons in these layers are neither inputs nor outputs.&lt;&#x2F;p&gt;
&lt;p&gt;    Up to now, we&#x27;ve been discussing neural networks where the output from one layer is used as input to the next layer. Such networks are called feedforward neural networks. This means there are no loops in the network - information is always passed forward, never passed back. If we did have loops, we&#x27;d end up with situations where the input to the σ function depended on the output. That&#x27;d be hard to make sense of, and so we&#x27;ll keep it outside the scope of this blog.&lt;&#x2F;p&gt;
&lt;p&gt;    However, There are artificial neural networks that make sense of the loops called &lt;a href=&quot;https:&#x2F;&#x2F;aws.amazon.com&#x2F;what-is&#x2F;recurrent-neural-network&#x2F;&quot;&gt;recurrent neural networks&lt;&#x2F;a&gt;. The idea of which is allowing neurons to fire only a few times or a fixed duration.&lt;&#x2F;p&gt;
&lt;p&gt;    Our program will solve the problem of classifying individual digits and not a string of numbers.
To recognize individual digits we will use a three-layer neural network:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;p2&#x2F;architecture3.png&quot; alt=&quot;alt text&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Our &lt;a href=&quot;https:&#x2F;&#x2F;yann.lecun.com&#x2F;exdb&#x2F;mnist&#x2F;&quot;&gt;training data&lt;&#x2F;a&gt; for the network will consist of many $28$ by $28$ pixel images of scanned handwritten digits, and so the input layer contains $784=28×28$ neurons. The input pixels are greyscale, with a value of $0.0$ representing white, a value of $1.0$ representing black, and in between values representing gradually darkening shades of grey.&lt;&#x2F;p&gt;
&lt;p&gt;    The second layer of the network is a hidden layer. We denote the number of neurons in this hidden layer by $n$, and we&#x27;ll experiment with different values for $n$. The example shown illustrates a small hidden layer, containing just $n=15$ neurons.&lt;&#x2F;p&gt;
&lt;p&gt;    The output layer of the network contains 10 neurons. If the first neuron fires, i.e., has an output $≈1$, then that will indicate that the network thinks the digit is a $0$. If the second neuron fires then that will indicate that the network thinks the digit is a $1$. And so on.&lt;&#x2F;p&gt;
&lt;p&gt;    A Computer Science perspective might wonder why we use 10 output neurons. After all, the goal of the network is to tell us which digit $(0,1,2,…,9)$ corresponds to the input image. A seemingly natural way of doing that is to use just $4$ output neurons, treating each neuron as taking on a binary value, depending on whether the neuron&#x27;s output is closer to 0 or to 1. Four neurons are enough to encode the answer, since $2^4=16$ is more than the 10 possible values for the input digit. Why should our network use 10 neurons instead? Isn&#x27;t that inefficient?&lt;&#x2F;p&gt;
&lt;p&gt;    This was my initial thought and turns out; one &lt;em&gt;could&lt;&#x2F;em&gt; implement a 4 output-neuron architecture, but the hidden layers seem to struggle with selecting features and they find 10 neurons simpler to push their outputs to. Although this is all just a heuristic, and people are free to try out different architectures just to play around.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;learning-with-gradient-descent&quot;&gt;Learning with gradient descent&lt;&#x2F;h1&gt;
&lt;p&gt;We&#x27;ll use the notation $x$ to denote a training input. It&#x27;ll be convenient to regard each training input $x$ as a $28×28=784$-dimensional vector. Each vector input represents the grey value from $0$ to $1$ for each pixel. For example, if a particular training image, $x$, depicts a $6$, then $y(x)=(0,0,0,0,0,0,1,0,0,0)^T$ is the desired output from the network.&lt;&#x2F;p&gt;
&lt;p&gt;    In order to quantify how correct the model is we could introduce a &amp;quot;cost&amp;quot; function (also called as loss function). Similar to how your teacher gives you varying amount of marks on a answer depending on how correct it is. This function allows us to determine how correct the model is and how confident it gives its results.&lt;&#x2F;p&gt;
&lt;p&gt;$$C(w,b) = {\frac1 {2n}} \sum_x ||y(x) - a||^2 \tag{5}$$&lt;&#x2F;p&gt;
&lt;p&gt;This equation is called &lt;a href=&quot;https:&#x2F;&#x2F;statisticsbyjim.com&#x2F;regression&#x2F;mean-squared-error-mse&#x2F;&quot;&gt;$mean \space squared \space error$&lt;&#x2F;a&gt; or a quadratic cost function. Here, &lt;&#x2F;p&gt;
&lt;p&gt;   $\bullet$ $w$ denotes the collection of all weights in the network,&lt;&#x2F;p&gt;
&lt;p&gt;   $\bullet$ $b$ all the biases, $n$ is the number of training inputs,&lt;&#x2F;p&gt;
&lt;p&gt;   $\bullet$ $a$ is the vector of outputs from the network when $x$ is input, and the sum is over&lt;br &#x2F;&gt;
    all training inputs, $x$.&lt;&#x2F;p&gt;
&lt;p&gt;   Of course, the output a depends on $x$, $w$ and $b$, but to keep the notation simple I haven&#x27;t explicitly indicated this dependence. The notation $∥v∥$ just denotes the usual length function for a vector $v$.&lt;&#x2F;p&gt;
&lt;p&gt;    The model has done a good job if it can find weights and biases so that $C(w,b)≈0$. By contrast, it&#x27;s not doing so well when $C(w,b)$ is large - that would mean that $y(x)$ is not close to the output a for a large number of inputs. So the aim of our training algorithm will be to minimize the cost $C(w,b)$ as a function of the weights and biases. We&#x27;ll minimize it using a method called gradient descent.&lt;&#x2F;p&gt;
&lt;p&gt;for a given cost function $C$ with parameters $v1$ and $v2$, the change in $C$ caused by changes in $v1$ and $v2$ is given by:&lt;&#x2F;p&gt;
&lt;p&gt;$$\Delta C \approx \frac{\partial C}{\partial v_1}\Delta v_1 + \frac{\partial C}{\partial v_2}\Delta v_2$$&lt;&#x2F;p&gt;
&lt;p&gt;We have to choose $\Delta v_1$ and $\Delta v_2$ such that $\Delta C$ turns out to be negative as to allow for the function to descend.&lt;&#x2F;p&gt;
&lt;p&gt;We&#x27;ll denote the gradient vector by $∇C$, i.e.:&lt;&#x2F;p&gt;
&lt;p&gt;$$\nabla C \equiv \left(\frac{\partial C}{\partial v_1}, \frac{\partial C}{\partial v_2}\right)^T$$&lt;&#x2F;p&gt;
&lt;p&gt;With these definitions, the expression for $ΔC$ can be rewritten as&lt;&#x2F;p&gt;
&lt;p&gt;$$\Delta C \approx \nabla C \cdot \Delta v $$&lt;&#x2F;p&gt;
&lt;p&gt;This equation allows us to choose Δv in a way so as to make ΔC negative. In particular, suppose we choose&lt;&#x2F;p&gt;
&lt;p&gt;$$Δv=−η∇C$$&lt;&#x2F;p&gt;
&lt;p&gt;Where $η$ is a small, positive number (also called as learning rate).&lt;&#x2F;p&gt;
&lt;p&gt;$$ΔC≈−η∇C⋅∇C=−η∥∇C∥^2$$&lt;&#x2F;p&gt;
&lt;p&gt;Because $∥∇C∥2≥0$, this guarantees that $ΔC≤0$, i.e., $C$ will always decrease, never increase.&lt;&#x2F;p&gt;
&lt;p&gt;$$\therefore v→v&#x27;=v−η∇C \tag{6}$$&lt;&#x2F;p&gt;
&lt;p&gt;If we keep doing this, over and over, we&#x27;ll keep decreasing $C$ until we reach (or get close to) a global minimum.&lt;&#x2F;p&gt;
&lt;p&gt;    You can think of this update rule as defining the gradient descent algorithm. It gives us a way of repeatedly changing the position v in order to find a minimum of the function $C$. The rule doesn&#x27;t always work - several things can go wrong and prevent gradient descent from finding the global minimum of $C$. But, in practice gradient descent often works extremely well.&lt;&#x2F;p&gt;
&lt;p&gt;How can we apply gradient descent to learn in a neural network? The idea is to use gradient descent to find the weights $w_k$ and biases $b_l$ which minimize the cost.&lt;&#x2F;p&gt;
&lt;p&gt;$$w&#x27;_k = w_k - \eta \frac{\partial C}{\partial w_k}$$
$$b&#x27;_l = b_l - \eta \frac{\partial C}{\partial b_l}$$&lt;&#x2F;p&gt;
&lt;p&gt;    An idea called stochastic gradient descent can be used to speed up learning. The idea is to estimate the gradient $∇C$ by computing $∇C_x$ for a &#x27;mini batch&#x27; of a small sample of randomly chosen training inputs. By averaging over this small sample it turns out that we can quickly get a good estimate of the true gradient $∇C$, and this helps speed up gradient descent, and thus learning.&lt;&#x2F;p&gt;
&lt;p&gt;    We pick a randomly chosen mini-batch of training inputs and train the model. We pick out another randomly chosen mini-batch and train with those. And so on, until we&#x27;ve exhausted the training inputs, which is said to complete an epoch of training. At that point we start over with a new training epoch.&lt;&#x2F;p&gt;
&lt;p&gt;    We can think of stochastic gradient descent as being like political polling: it&#x27;s much easier to sample a small mini-batch than it is to apply gradient descent to the full batch, just as carrying out a poll is easier than running a full election.&lt;&#x2F;p&gt;
&lt;p&gt;All this information until now should be enough for implementing the classification model. An implementation in python is written below with numpy.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;the-code&quot;&gt;The code&lt;&#x2F;h1&gt;
&lt;p&gt;You can run a copy of it in your local machine (I tried it on a linux machine with 16gb of ram with no GPU). You might find some problems with importing keras.datasets, you could replace it with &lt;code&gt;from tensorflow.keras.datasets import mnist&lt;&#x2F;code&gt; (or even manually download it into your machine) as per your convenience.&lt;&#x2F;p&gt;
&lt;p&gt;    Note that this model generates ~75% accuracy (better than 10% from random guessing) and is not at all production ready, but is a very very simplified version with only sigmoid-activation functions (compared to Rectifiers and softmax activations) for educational purposes.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#0f1419;color:#bfbab0;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;import &lt;&#x2F;span&gt;&lt;span&gt;pandas &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;as &lt;&#x2F;span&gt;&lt;span&gt;pd
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;import &lt;&#x2F;span&gt;&lt;span&gt;numpy &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;as &lt;&#x2F;span&gt;&lt;span&gt;np
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;import &lt;&#x2F;span&gt;&lt;span&gt;pickle
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;from &lt;&#x2F;span&gt;&lt;span&gt;keras&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;datasets &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;import &lt;&#x2F;span&gt;&lt;span&gt;mnist
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;import &lt;&#x2F;span&gt;&lt;span&gt;matplotlib&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;pyplot &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;as &lt;&#x2F;span&gt;&lt;span&gt;plt
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;def &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;sigmoid&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;Z&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&#x2F; &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span&gt;np&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;exp&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span&gt;Z))
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;def &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;derivative_sigmoid&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;Z&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;    sig &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;sigmoid&lt;&#x2F;span&gt;&lt;span&gt;(Z)
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span&gt;sig &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;- &lt;&#x2F;span&gt;&lt;span&gt;sig)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;def &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;init_params&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;size&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;    W1 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;np&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;random&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;rand&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;10&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span&gt;size) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;- &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;5
&lt;&#x2F;span&gt;&lt;span&gt;    b1 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;np&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;random&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;rand&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;10&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;- &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;5
&lt;&#x2F;span&gt;&lt;span&gt;    W2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;np&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;random&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;rand&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;10&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;10&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;- &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;5
&lt;&#x2F;span&gt;&lt;span&gt;    b2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;np&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;random&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;rand&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;10&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;- &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;5
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span&gt;W1,b1,W2,b2
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;def &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;forward_propagation&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;X&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;W1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;b1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;b2&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;    Z1 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;W1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;dot&lt;&#x2F;span&gt;&lt;span&gt;(X) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span&gt;b1 
&lt;&#x2F;span&gt;&lt;span&gt;    A1 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;sigmoid&lt;&#x2F;span&gt;&lt;span&gt;(Z1) 
&lt;&#x2F;span&gt;&lt;span&gt;    Z2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;dot&lt;&#x2F;span&gt;&lt;span&gt;(A1) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span&gt;b2
&lt;&#x2F;span&gt;&lt;span&gt;    A2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;sigmoid&lt;&#x2F;span&gt;&lt;span&gt;(Z2)
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span&gt;Z1, A1, Z2, A2
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;def &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;mse_loss&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;A2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;Y&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;m&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;    Y_one_hot &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;np&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;identity&lt;&#x2F;span&gt;&lt;span&gt;(A2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;shape[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;])[Y]&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;T 
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span&gt;np&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;mean&lt;&#x2F;span&gt;&lt;span&gt;(np&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;sum&lt;&#x2F;span&gt;&lt;span&gt;((A2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;- &lt;&#x2F;span&gt;&lt;span&gt;Y_one_hot)&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;**&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;axis&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;))
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;def &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;backward_propagation&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;X&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;Y&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;A1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;A2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;Z1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;m&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;    Y_one_hot &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;np&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;identity&lt;&#x2F;span&gt;&lt;span&gt;(A2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;shape[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;])[Y]&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;T 
&lt;&#x2F;span&gt;&lt;span&gt;    dZ2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span&gt;(A2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;- &lt;&#x2F;span&gt;&lt;span&gt;Y_one_hot) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&#x2F; &lt;&#x2F;span&gt;&lt;span&gt;m
&lt;&#x2F;span&gt;&lt;span&gt;    dW2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;dZ2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;dot&lt;&#x2F;span&gt;&lt;span&gt;(A1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;T)
&lt;&#x2F;span&gt;&lt;span&gt;    db2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;np&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;sum&lt;&#x2F;span&gt;&lt;span&gt;(dZ2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;axis&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;keepdims&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;True&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;    dZ1 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;T&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;dot&lt;&#x2F;span&gt;&lt;span&gt;(dZ2) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;derivative_sigmoid&lt;&#x2F;span&gt;&lt;span&gt;(Z1)
&lt;&#x2F;span&gt;&lt;span&gt;    dW1 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;dZ1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;dot&lt;&#x2F;span&gt;&lt;span&gt;(X&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;T)
&lt;&#x2F;span&gt;&lt;span&gt;    db1 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;np&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;sum&lt;&#x2F;span&gt;&lt;span&gt;(dZ1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;axis&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;keepdims&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;True&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span&gt;dW1, db1, dW2, db2
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;def &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;update_params&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;alpha&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;W1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;b1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;b2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;dW1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;db1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;dW2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;db2&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;    W1 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;-= &lt;&#x2F;span&gt;&lt;span&gt;alpha &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span&gt;dW1
&lt;&#x2F;span&gt;&lt;span&gt;    b1 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;-= &lt;&#x2F;span&gt;&lt;span&gt;alpha &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span&gt;np&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;reshape&lt;&#x2F;span&gt;&lt;span&gt;(db1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;10&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;))
&lt;&#x2F;span&gt;&lt;span&gt;    W2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;-= &lt;&#x2F;span&gt;&lt;span&gt;alpha &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span&gt;dW2
&lt;&#x2F;span&gt;&lt;span&gt;    b2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;-= &lt;&#x2F;span&gt;&lt;span&gt;alpha &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span&gt;np&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;reshape&lt;&#x2F;span&gt;&lt;span&gt;(db2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;10&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;))
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span&gt;W1, b1, W2, b2
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;def &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;get_predictions&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;A2&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span&gt;np&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;argmax&lt;&#x2F;span&gt;&lt;span&gt;(A2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;def &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;get_accuracy&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;predictions&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;Y&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span&gt;np&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;sum&lt;&#x2F;span&gt;&lt;span&gt;(predictions &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;== &lt;&#x2F;span&gt;&lt;span&gt;Y)&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&#x2F;&lt;&#x2F;span&gt;&lt;span&gt;Y&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;size
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;def &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;gradient_descent&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;X&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;Y&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;alpha&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;iterations&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;    size, m &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;X&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;shape
&lt;&#x2F;span&gt;&lt;span&gt;    W1, b1, W2, b2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;init_params&lt;&#x2F;span&gt;&lt;span&gt;(size)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;in &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f07178;&quot;&gt;range&lt;&#x2F;span&gt;&lt;span&gt;(iterations):
&lt;&#x2F;span&gt;&lt;span&gt;        Z1, A1, Z2, A2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;forward_propagation&lt;&#x2F;span&gt;&lt;span&gt;(X&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b2)
&lt;&#x2F;span&gt;&lt;span&gt;        dW1, db1, dW2, db2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;backward_propagation&lt;&#x2F;span&gt;&lt;span&gt;(X&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;Y&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;A1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;A2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;Z1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;m)
&lt;&#x2F;span&gt;&lt;span&gt;        W1, b1, W2, b2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;update_params&lt;&#x2F;span&gt;&lt;span&gt;(alpha&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;dW1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;db1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;dW2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;db2)
&lt;&#x2F;span&gt;&lt;span&gt;        
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;(i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;+&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;% &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#39bae6;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt;(iterations&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;10&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;== &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;:
&lt;&#x2F;span&gt;&lt;span&gt;            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f07178;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;f&lt;&#x2F;span&gt;&lt;span style=&quot;color:#c2d94c;&quot;&gt;&amp;quot;Iteration: &lt;&#x2F;span&gt;&lt;span&gt;{i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;+&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;}&lt;&#x2F;span&gt;&lt;span style=&quot;color:#c2d94c;&quot;&gt; &#x2F; &lt;&#x2F;span&gt;&lt;span&gt;{iterations}&lt;&#x2F;span&gt;&lt;span style=&quot;color:#c2d94c;&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;            prediction &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;get_predictions&lt;&#x2F;span&gt;&lt;span&gt;(A2)
&lt;&#x2F;span&gt;&lt;span&gt;            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f07178;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;f&lt;&#x2F;span&gt;&lt;span style=&quot;color:#c2d94c;&quot;&gt;&amp;#39;Accuracy: &lt;&#x2F;span&gt;&lt;span&gt;{&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;get_accuracy&lt;&#x2F;span&gt;&lt;span&gt;(prediction&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;Y)&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;:.3%&lt;&#x2F;span&gt;&lt;span&gt;}&lt;&#x2F;span&gt;&lt;span style=&quot;color:#c2d94c;&quot;&gt;&amp;#39;&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f07178;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;f&lt;&#x2F;span&gt;&lt;span style=&quot;color:#c2d94c;&quot;&gt;&amp;#39;MSE Loss: &lt;&#x2F;span&gt;&lt;span&gt;{&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;mse_loss&lt;&#x2F;span&gt;&lt;span&gt;(A2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;Y&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;m)&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;:.4f&lt;&#x2F;span&gt;&lt;span&gt;}&lt;&#x2F;span&gt;&lt;span style=&quot;color:#c2d94c;&quot;&gt;&amp;#39;&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span&gt;W1, b1, W2, b2
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;def &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;make_predictions&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;X&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;W1 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;b1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;b2&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#39bae6;&quot;&gt;_&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#39bae6;&quot;&gt;_&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#39bae6;&quot;&gt;_&lt;&#x2F;span&gt;&lt;span&gt;, A2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;forward_propagation&lt;&#x2F;span&gt;&lt;span&gt;(X&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b2)
&lt;&#x2F;span&gt;&lt;span&gt;    predictions &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;get_predictions&lt;&#x2F;span&gt;&lt;span&gt;(A2)
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span&gt;predictions
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;def &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;show_prediction&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;index&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;X&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;Y&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;W1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;b1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;b2&lt;&#x2F;span&gt;&lt;span&gt;):
&lt;&#x2F;span&gt;&lt;span&gt;   &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#5c6773;&quot;&gt;# None =&amp;gt; creates a new axis of dimension 1, this has the effect of transposing X[:,index] which is an np.array of dimension 1 (row) and which becomes a vector (column)
&lt;&#x2F;span&gt;&lt;span&gt;     &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#5c6773;&quot;&gt;# which corresponds to what is requested by make_predictions which expects a matrix whose columns are the pixels of the image, there we give a single column
&lt;&#x2F;span&gt;&lt;span&gt;    vect_X &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;X[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;:&lt;&#x2F;span&gt;&lt;span&gt;, index,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;None&lt;&#x2F;span&gt;&lt;span&gt;]
&lt;&#x2F;span&gt;&lt;span&gt;    prediction &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;make_predictions&lt;&#x2F;span&gt;&lt;span&gt;(vect_X&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b2)
&lt;&#x2F;span&gt;&lt;span&gt;    label &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;Y[index]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f07178;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#c2d94c;&quot;&gt;&amp;quot;Prediction: &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;prediction)
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f07178;&quot;&gt;print&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#c2d94c;&quot;&gt;&amp;quot;Label: &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;label)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    current_image &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;vect_X&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;reshape&lt;&#x2F;span&gt;&lt;span&gt;((WIDTH&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;HEIGHT)) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span&gt;SCALE_FACTOR
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    plt&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;gray&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;    plt&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;imshow&lt;&#x2F;span&gt;&lt;span&gt;(current_image&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;interpolation&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#c2d94c;&quot;&gt;&amp;#39;nearest&amp;#39;&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;    plt&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;show&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#5c6773;&quot;&gt;#MAIN
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;(X_train&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;Y_train), (X_test&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;Y_test) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;mnist&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;load_data&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;SCALE_FACTOR &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;255 &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#5c6773;&quot;&gt;# to prevent overflow on exp();
&lt;&#x2F;span&gt;&lt;span&gt;WIDTH &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;X_train&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;shape[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;]
&lt;&#x2F;span&gt;&lt;span&gt;HEIGHT &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;X_train&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;shape[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;X_train &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;X_train&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;reshape&lt;&#x2F;span&gt;&lt;span&gt;(X_train&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;shape[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;]&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span&gt;WIDTH&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;*&lt;&#x2F;span&gt;&lt;span&gt;HEIGHT)&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;T &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&#x2F; &lt;&#x2F;span&gt;&lt;span&gt;SCALE_FACTOR
&lt;&#x2F;span&gt;&lt;span&gt;X_test &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;X_test&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;reshape&lt;&#x2F;span&gt;&lt;span&gt;(X_test&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;shape[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;]&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span&gt;WIDTH&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;*&lt;&#x2F;span&gt;&lt;span&gt;HEIGHT)&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span&gt;T  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&#x2F; &lt;&#x2F;span&gt;&lt;span&gt;SCALE_FACTOR
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;W1, b1, W2, b2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;gradient_descent&lt;&#x2F;span&gt;&lt;span&gt;(X_train&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;Y_train&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;25&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;200&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;with &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f07178;&quot;&gt;open&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#c2d94c;&quot;&gt;&amp;quot;trained_params.pkl&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#c2d94c;&quot;&gt;&amp;quot;wb&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;as &lt;&#x2F;span&gt;&lt;span&gt;dump_file:
&lt;&#x2F;span&gt;&lt;span&gt;    pickle&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;dump&lt;&#x2F;span&gt;&lt;span&gt;((W1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b2)&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span&gt;dump_file)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;with &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f07178;&quot;&gt;open&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#c2d94c;&quot;&gt;&amp;quot;trained_params.pkl&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span style=&quot;color:#c2d94c;&quot;&gt;&amp;quot;rb&amp;quot;&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;as &lt;&#x2F;span&gt;&lt;span&gt;dump_file:
&lt;&#x2F;span&gt;&lt;span&gt;    W1, b1, W2, b2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt;pickle&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;load&lt;&#x2F;span&gt;&lt;span&gt;(dump_file)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;show_prediction&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span&gt;X_test&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;Y_test&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b2)
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;show_prediction&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span&gt;X_test&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;Y_test&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b2)
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;show_prediction&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span&gt;X_test&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;Y_test&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b2)
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;show_prediction&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;100&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span&gt;X_test&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;Y_test&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b2)
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;show_prediction&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;200&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span&gt;X_test&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;Y_test&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;W2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span&gt;b2)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Quake III&#x27;s Fast Inverse Square Root Algorithm</title>
        <published>2024-01-26T00:00:00+00:00</published>
        <updated>2024-01-26T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/posts/fast-inverse-square-root-algorithm/"/>
        <id>/posts/fast-inverse-square-root-algorithm/</id>
        
        <content type="html" xml:base="/posts/fast-inverse-square-root-algorithm/">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;&#x2F;h1&gt;
&lt;p&gt;    The &lt;strong&gt;Fast inverse square root&lt;&#x2F;strong&gt; or &lt;strong&gt;0x5F3759DF&lt;&#x2F;strong&gt; is an algorithm that approximates $f(x) = 1&#x2F;\sqrt x$  where $x$ is a 32-bit floating-point number. First observed in the game engine for Quake III Arena in 1999. Which was heavily based on 3D graphics.&lt;&#x2F;p&gt;
&lt;p&gt;In this piece of writing I will try my best on explaining the mathematical, physical and computational reason of it&#x27;s existence and why it is such an ingenius hack.&lt;&#x2F;p&gt;
&lt;p&gt;The reason I am doing this is because this algorithm implements concepts from statistical approximation in mathematics, 3D-vectors in theoretical physics, the numerical data storing system in computer architecture, C language, and some bitwise black magic. All of which were taught to me in my 1st and 2nd years of university, just seperately.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;the-code&quot;&gt;The Code&lt;&#x2F;h1&gt;
&lt;p&gt;For you impatient, goldfish-brained, tiktok people, here&#x27;s the function of the code from Quake III Arena, stripped of the C directives (basic boilerplate), with the original comments in place.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;c&quot; style=&quot;background-color:#0f1419;color:#bfbab0;&quot; class=&quot;language-c &quot;&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;float &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;q_rsqrt&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;float &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;number&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;long&lt;&#x2F;span&gt;&lt;span&gt; i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;float&lt;&#x2F;span&gt;&lt;span&gt; x2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span&gt; y&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;const float&lt;&#x2F;span&gt;&lt;span&gt; threehalfs &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;5&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;F&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  x2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; number &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;5&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;F&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;  y  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; number&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;  i  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= * &lt;&#x2F;span&gt;&lt;span&gt;( &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;long &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&amp;amp;&lt;&#x2F;span&gt;&lt;span&gt;y&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;                       &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#5c6773;&quot;&gt;&#x2F;&#x2F; evil floating point bit level hacking
&lt;&#x2F;span&gt;&lt;span&gt;  i  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0x5f3759df &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;- &lt;&#x2F;span&gt;&lt;span&gt;( i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&amp;gt;&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1 &lt;&#x2F;span&gt;&lt;span&gt;)&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;               &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#5c6773;&quot;&gt;&#x2F;&#x2F; what the fuck?
&lt;&#x2F;span&gt;&lt;span&gt;  y  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= * &lt;&#x2F;span&gt;&lt;span&gt;( &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;float &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&amp;amp;&lt;&#x2F;span&gt;&lt;span&gt;i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;  y  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span&gt;( threehalfs &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;- &lt;&#x2F;span&gt;&lt;span&gt;( x2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;*&lt;&#x2F;span&gt;&lt;span&gt; y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;*&lt;&#x2F;span&gt;&lt;span&gt; y ) )&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;   &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#5c6773;&quot;&gt;&#x2F;&#x2F; 1st iteration
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#5c6773;&quot;&gt;&#x2F;&#x2F; y  = y * ( threehalfs - ( x2 * y * y ) );   &#x2F;&#x2F; 2nd iteration, this can be removed
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;return&lt;&#x2F;span&gt;&lt;span&gt; y&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h1 id=&quot;why-does-a-game-engine-need-this-function&quot;&gt;Why does a game engine need this function?&lt;&#x2F;h1&gt;
&lt;p&gt;If you want to implement lighting or reflections in your game engine, it is helpful if the vectors in your calculations are &lt;em&gt;normalised&lt;&#x2F;em&gt; to have magnitude 1; If you don&#x27;t normalise it, things can go wrong during computations.&lt;br &#x2F;&gt;
&lt;br &#x2F;&gt;
For normalising a 3D vector:&lt;br &#x2F;&gt;
$$\hat{a} = \frac{\vec{A}}{\sqrt{x^2+y^2+z^2}}$$ or &lt;br &#x2F;&gt;
$$\hat{a} = \vec{A}*\frac{1}{\sqrt{x^2+y^2+z^2}}$$ ie.&lt;&#x2F;p&gt;
&lt;p&gt;$$\hat{a} = \vec{A}*\frac{1}{|A|}$$&lt;&#x2F;p&gt;
&lt;p&gt;multiplication and addition is easy for computers. For reasons I will mention later, the square root is relatively, an extremely slow piece of computation. And division is not much better either.&lt;&#x2F;p&gt;
&lt;p&gt;For a game engine, this normalisation is carried out over several thousands of surfaces each second. And these slow pieces of computations break the game because it can&#x27;t catch up with the real-time need of rendering these surfaces. Therefore we need a solution that can solve this problem, even by a little bit.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;why-a-new-algorithm&quot;&gt;Why a new algorithm?&lt;&#x2F;h1&gt;
&lt;p&gt;If you are a common pleb, you would just do something like this:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;c&quot; style=&quot;background-color:#0f1419;color:#bfbab0;&quot; class=&quot;language-c &quot;&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;#include &lt;&#x2F;span&gt;&lt;span style=&quot;color:#c2d94c;&quot;&gt;&amp;lt;math.h&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;float &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;q_rsqrt&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;float &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;number&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f07178;&quot;&gt;sqrt&lt;&#x2F;span&gt;&lt;span&gt;(x)&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The ALU (Arithmetic and logic unit) in our CPUs have specialized system of gates built for addition and multiplication, but not for division and subtraction. Although subtraction has a quick fix with &lt;a href=&quot;https:&#x2F;&#x2F;www.geeksforgeeks.org&#x2F;subtraction-of-two-numbers-using-2s-complement&#x2F;&quot;&gt;2&#x27;s complement method&lt;&#x2F;a&gt;, Division is still a more complex calculation, even more complex is square root. Intel and other manufacturers could, in theory add specialized gates for them, but it is very expensive. For thousands of calculations a second(like in our case), these gates are simply not feasable. So we need something that can be faster. The fast inverse square root is an approximation with an error of atmost 1%, while being about 3x as fast.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;floating-point-numbers&quot;&gt;Floating point numbers&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Before we proceed any further, I think it is required to mention how computers store floats. This is going to be very boring, so there&#x27;s a TLDR after this.&lt;&#x2F;p&gt;
&lt;p&gt;Floats are expressed in a similar fashion to scientific notations; namely the &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;IEEE_754&quot;&gt;IEEE-754 standard&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;The smart folks at IEEE set it in this form&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;p1&#x2F;Untitled-1.svg&quot; alt=&quot;images&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The first bit is a sign bit, which is 1 when the number is negative and 0 when positive. Since we&#x27;ll be dealing exclusively with positive numbers with this algorithm (we would never need to calculate $\frac{1}{\sqrt{-5}}$ or something) the sign bit will always be 0.   &lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;It&#x27;s followed by 8 bits of exponents in Excess-127 format. For context, you can use 8 bits represent exponents from 0 to 255; However, we need to represent fractions (ie, negative exponents) too, so we shift the exponents by 127. Now we can represent exponents from -127 to 128; so the power 4, instead of 00000100, will be represented as 10000011. This shifting is called Excess-127 (because we&#x27;re shifting exponents by 127).   &lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;The remaining 23 bits store the fractional part, from 1.0000000.... to 1.11111.... (so $[1, 2)$ in binary). But, the IEEE realized that the first digit in scientific notation will always be 1, so they made it part of the equation. Therefore, the 23 bits now store only the Mantissa (The part after the decimal point).&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Note: What we&#x27;ve discussed just now is actually a subset of the IEEE-754 standard, which describes normalised numbers; denormalised numbers, NaN (not a number), 0 and -0 will never be accepted by our algorithm, so we won&#x27;t discuss them here.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;tldr&quot;&gt;TLDR&lt;&#x2F;h2&gt;
&lt;p&gt;The number that we recieve will have 32 bits, first one being 0, next 8 being the exponent(E) and the remaining 23 being the Mantissa(M).&lt;&#x2F;p&gt;
&lt;p&gt;written in the form of ${2^{23}}*E + M$.&lt;&#x2F;p&gt;
&lt;p&gt;$M$ = 01001110010000000000000&lt;&#x2F;p&gt;
&lt;p&gt;$E$ = 10001001&lt;&#x2F;p&gt;
&lt;p&gt;${2^{23}}*E$ = 10001001 00000000000000000000000&lt;&#x2F;p&gt;
&lt;p&gt;${2^{23}}*E + M$ = 10001001 01001110010000000000000&lt;&#x2F;p&gt;
&lt;h1 id=&quot;bits-and-numbers&quot;&gt;Bits and Numbers&lt;&#x2F;h1&gt;
&lt;p&gt;From our Floating point thing, our number can be represented as:&lt;&#x2F;p&gt;
&lt;p&gt;$$n = \left(1+ \frac{M}{2^{23}}\right)*2^{E-127}$$&lt;&#x2F;p&gt;
&lt;p&gt;Taking $log_2$ on both sides:&lt;&#x2F;p&gt;
&lt;p&gt;$$log_2n = log_2\left(\left(1+ \frac{M}{2^{23}}\right)*2^{E-127}\right)$$&lt;&#x2F;p&gt;
&lt;p&gt;Simplifying:&lt;&#x2F;p&gt;
&lt;p&gt;$$log_2n = log_2\left(1+ \frac{M}{2^{23}}\right)+2^{E-127}$$&lt;&#x2F;p&gt;
&lt;p&gt;Using $log_2(1+x) \approx x$ (&lt;a href=&quot;https:&#x2F;&#x2F;math.stackexchange.com&#x2F;a&#x2F;1111064&quot;&gt;source&lt;&#x2F;a&gt;):&lt;&#x2F;p&gt;
&lt;p&gt;$$log_2n = \frac{M}{2^{23}}+E+\mu-127$$ &lt;&#x2F;p&gt;
&lt;p&gt;Note: the $\mu$ value is 0.0430, this value shifts the approximation to reduce the average error when $0 \leq x \leq 1$.&lt;&#x2F;p&gt;
&lt;p&gt;Multiplying and dividing by $2^{23}$&lt;&#x2F;p&gt;
&lt;p&gt;$$log_2n = \frac{1}{2^{23}}\left(M+2^{23}*E\right)+\mu-127$$&lt;&#x2F;p&gt;
&lt;p&gt;Now we see that we just got the bit representation of our number. Therefore, the log of our number stores the bit representiaton, abeit with some scaling and shifting.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;the-steps&quot;&gt;The Steps&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;iterating-through-the-code&quot;&gt;Iterating through the code&lt;&#x2F;h2&gt;
&lt;p&gt;Looking at the code again, the first 4 lines don&#x27;t seem that harmful.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;c&quot; style=&quot;background-color:#0f1419;color:#bfbab0;&quot; class=&quot;language-c &quot;&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;float &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;q_rsqrt&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;float &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;number&lt;&#x2F;span&gt;&lt;span&gt;){         &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;32&lt;&#x2F;span&gt;&lt;span&gt; bit decimal &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffb454;&quot;&gt;number &lt;&#x2F;span&gt;&lt;span&gt;(input)
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;long&lt;&#x2F;span&gt;&lt;span&gt; i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;                            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;32&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span&gt;bit integer number
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;float&lt;&#x2F;span&gt;&lt;span&gt; x2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span&gt; y&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;                       &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;32&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span&gt;bit decimal numbers
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;const float&lt;&#x2F;span&gt;&lt;span&gt; threehalfs &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;5&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;F&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;     &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;3&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;,&lt;&#x2F;span&gt;&lt;span&gt; also &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;32&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span&gt;bit&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The next two aren&#x27;t that bad either:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;c&quot; style=&quot;background-color:#0f1419;color:#bfbab0;&quot; class=&quot;language-c &quot;&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span&gt;  x2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; number &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;5&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;F&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;                &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&amp;gt;&lt;&#x2F;span&gt;&lt;span&gt; Assign number&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt; to x2
&lt;&#x2F;span&gt;&lt;span&gt;  y  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; number&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;                       &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&amp;gt;&lt;&#x2F;span&gt;&lt;span&gt; Assign number to y
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;But then, all hell seems to break loose, what is &lt;em&gt;i&lt;&#x2F;em&gt;? What is 0x5f3759df? Why declare a variable for 1.5 and not for 0x5f3759df? Why are there so many pointers?&lt;&#x2F;p&gt;
&lt;p&gt;The comments don&#x27;t seem to help either. But it hints that there&#x27;s three steps in the process, namely:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;evil floating point bit hack&lt;&#x2F;li&gt;
&lt;li&gt;what the fuck&lt;&#x2F;li&gt;
&lt;li&gt;1st iteration (spoiler: Newton&#x27;s approximations)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;evil-floating-point-bit-hack&quot;&gt;Evil floating point bit hack&lt;&#x2F;h2&gt;
&lt;pre data-lang=&quot;c&quot; style=&quot;background-color:#0f1419;color:#bfbab0;&quot; class=&quot;language-c &quot;&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span&gt;i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= *&lt;&#x2F;span&gt;&lt;span&gt;( &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;long &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&amp;amp;&lt;&#x2F;span&gt;&lt;span&gt;y&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now the problem with floats in C is that it doesn&#x27;t support &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bit_manipulation&quot;&gt;bit manipulations&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;But longs do.&lt;&#x2F;p&gt;
&lt;p&gt;So this line hacks C into thinking that the content stored in &lt;code&gt;y&lt;&#x2F;code&gt;&#x27;s address is actually a long, and then stores the data into i, which is actually a long.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;code&gt;&amp;amp;y&lt;&#x2F;code&gt; $\Rightarrow$ get the memory address of y.&lt;br &#x2F;&gt;
&lt;code&gt;(long * )&amp;amp;y&lt;&#x2F;code&gt; $\Rightarrow$ turn the data stored in the address y into a long.&lt;br &#x2F;&gt;
&lt;code&gt;i = *( long * ) &amp;amp;y;&lt;&#x2F;code&gt; $\Rightarrow$ store that data in i.&lt;&#x2F;p&gt;
&lt;p&gt;Now we know that both floats and longs have 32 bit memory allocations, So this line creates a one-to-one mapping of the bits from &lt;code&gt;y&lt;&#x2F;code&gt; to &lt;code&gt;i&lt;&#x2F;code&gt;.
Now our number can go through bit manipulations.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-the-fuck&quot;&gt;What the fuck?&lt;&#x2F;h2&gt;
&lt;pre data-lang=&quot;c&quot; style=&quot;background-color:#0f1419;color:#bfbab0;&quot; class=&quot;language-c &quot;&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span&gt;i  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;0x5f3759df &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;- &lt;&#x2F;span&gt;&lt;span&gt;( i &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&amp;gt;&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29718;&quot;&gt;1 &lt;&#x2F;span&gt;&lt;span&gt;)&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;; 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Let&#x27;s talk about bit manipulation, namely shifting. In binary, shifting left doubles the number and shifting right halves it, while rounding it off.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Let: x = 1101 = 13&lt;&#x2F;li&gt;
&lt;li&gt;(x &amp;lt;&amp;lt; 1) = 11010 = 26&lt;&#x2F;li&gt;
&lt;li&gt;(x &amp;gt;&amp;gt; 1) = 110 = 6&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Lets see how bit shifting affects exponents:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;let our exponent be $n^x$.&lt;&#x2F;li&gt;
&lt;li&gt;left shifting a exponent doubles it. ie: $n^{2x}$&lt;&#x2F;li&gt;
&lt;li&gt;right shifting a exponent gives us the square root. ie: $n^{\frac{x}{2}}$&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;We have our number $y$ and we have to find out $\frac{1}{\sqrt{y}}$&lt;&#x2F;p&gt;
&lt;p&gt;But as we&#x27;ve seen:&lt;&#x2F;p&gt;
&lt;p&gt;$$log_2(y) \approx i$$&lt;&#x2F;p&gt;
&lt;p&gt;so let&#x27;s just calculate &lt;&#x2F;p&gt;
&lt;p&gt;$$log_2\left(\frac{1}{\sqrt{y}}\right)$$&lt;&#x2F;p&gt;
&lt;p&gt;which is equal to:&lt;&#x2F;p&gt;
&lt;p&gt;$$-\frac{1}{2}log_2(y)$$&lt;&#x2F;p&gt;
&lt;p&gt;Calculating this is stupidly easy. &amp;quot;But you just told me that division is difficult!!1!!&amp;quot; Yes but remember bit shifting???&lt;br &#x2F;&gt;
Just do &lt;code&gt;-(i &amp;gt;&amp;gt; 1)&lt;&#x2F;code&gt; and you&#x27;re all set.&lt;&#x2F;p&gt;
&lt;p&gt;Now you might be wondering how and why do we have &lt;code&gt;0x5f3759df&lt;&#x2F;code&gt; in the line. Go to the end of &lt;a href=&quot;https:&#x2F;&#x2F;mayukh-chr.github.io&#x2F;posts&#x2F;fast-inverse-square-root-algorithm&#x2F;#bits-and-numbers&quot;&gt;this&lt;&#x2F;a&gt; and read &amp;quot;abeit with some scaling and shifting.&amp;quot;. Meaning that we need to scale and shift it back by some constant.&lt;&#x2F;p&gt;
&lt;p&gt;Let $$log(\Gamma) = log\left(\frac{1}{\sqrt{y}}\right)$$&lt;&#x2F;p&gt;
&lt;p&gt;which equals to&lt;&#x2F;p&gt;
&lt;p&gt;$$log(\Gamma) = -\frac{1}{2}log_2(y)$$&lt;&#x2F;p&gt;
&lt;p&gt;Now we replace the logarithm with the bit representation&lt;&#x2F;p&gt;
&lt;p&gt;$$\frac{1}{2^{23}}\left(M_\Gamma + 2^{23}*E_\Gamma\right) + \mu -127 = -\frac{1}{2}\left(\frac{1}{2^{23}}(M_\Gamma + 2^{23}*E_\Gamma) + \mu -127\right)$$&lt;&#x2F;p&gt;
&lt;p&gt;Calculating for $\left(M_\Gamma + 2^{23}*E_\Gamma\right)$&lt;&#x2F;p&gt;
&lt;p&gt;$$\left(M_\Gamma + 2^{23}*E_\Gamma\right) = \frac{3}{2}2^{23}\left(127-\mu\right)- \frac{1}{2} \left(M_y + 2^{23}*E_y\right)$$&lt;&#x2F;p&gt;
&lt;p&gt;where: $\frac{3}{2}2^{23}\left(127-0.0430\right) \approx$ 0x5F3759DF.&lt;&#x2F;p&gt;
&lt;p&gt;Therefore:&lt;&#x2F;p&gt;
&lt;p&gt;= 0x5F3759DF - (i &amp;gt;&amp;gt; 1)   (Note: Much later a more accurate constant was derived: 0x5F375A86, but we&#x27;ll ignore that for now.)&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;c&quot; style=&quot;background-color:#0f1419;color:#bfbab0;&quot; class=&quot;language-c &quot;&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span&gt;y  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;= * &lt;&#x2F;span&gt;&lt;span&gt;( &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;float &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;&amp;amp;&lt;&#x2F;span&gt;&lt;span&gt;i&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is just reversing the steps of the evil bit hack to get back the actual approximation of those bits.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;first-iteration&quot;&gt;First Iteration&lt;&#x2F;h2&gt;
&lt;pre data-lang=&quot;c&quot; style=&quot;background-color:#0f1419;color:#bfbab0;&quot; class=&quot;language-c &quot;&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span&gt;y  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span&gt;( threehalfs &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;- &lt;&#x2F;span&gt;&lt;span&gt;( x2 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;*&lt;&#x2F;span&gt;&lt;span&gt; y &lt;&#x2F;span&gt;&lt;span style=&quot;color:#f29668;&quot;&gt;*&lt;&#x2F;span&gt;&lt;span&gt; y ) )&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;After the previous step, we have a pretty good approximation but we did pick up some error terms here and there, but we can use &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Newton%27s_method&quot;&gt;Newton&#x27;s approximation&lt;&#x2F;a&gt; to get a close result.&lt;&#x2F;p&gt;
&lt;p&gt;Newton&#x27;s method finds a root of an equation. ie it finds an $x$ for which $f(x) = 0$. You repeat this process until you&#x27;re satisfied with your solution. But in this case, our initial approximation is good enough that one iteration of it gets our error to $\leq1%$.&lt;&#x2F;p&gt;
&lt;p&gt;The only thing that newton&#x27;s method needs is a function and it&#x27;s derivative. To put it simply:&lt;&#x2F;p&gt;
&lt;p&gt;$$x_{new} = x - \frac{f(x)}{f\prime(x)}$$&lt;&#x2F;p&gt;
&lt;p&gt;here it&#x27;s: &lt;&#x2F;p&gt;
&lt;p&gt;$$f(y) = 0 = \frac{1}{y^2}-x$$&lt;&#x2F;p&gt;
&lt;p&gt;$$\because f(y) = 0$$
$$\therefore y = \frac{1}{\sqrt{x}}$$&lt;&#x2F;p&gt;
&lt;p&gt;therefore using newton&#x27;s method:&lt;&#x2F;p&gt;
&lt;p&gt;$$f(y) = \frac{1}{y^2}-x \space and \space  f\prime(y) =  -\frac{2}{y^3}$$&lt;&#x2F;p&gt;
&lt;p&gt;$$y_{n+1} = y_n - \frac{f(y_n)}{f\prime(y_n)}$$
which is equal to 
$$y_{n+1} = \frac{y_n\left(3-xy_n^2\right)}{2} $$&lt;&#x2F;p&gt;
&lt;p&gt;which is the last line.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;c&quot; style=&quot;background-color:#0f1419;color:#bfbab0;&quot; class=&quot;language-c &quot;&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span style=&quot;color:#ff7733;&quot;&gt;return&lt;&#x2F;span&gt;&lt;span&gt; y&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bfbab0cc;&quot;&gt;;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff3333;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;just return the result that we just got. and you&#x27;re done.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;subsequent-improvements&quot;&gt;Subsequent Improvements&lt;&#x2F;h1&gt;
&lt;p&gt;It is not known precisely how the exact value for the magic number was determined. But many speculate it&#x27;s been through trial and error. Chris Lomont developed a function to minimize approximation error by choosing the magic number R R over a range. He first computed the optimal constant for the linear approximation step as 0x5F37642F, close to 0x5F3759DF, but this new constant gave slightly less accuracy after one iteration of Newton&#x27;s method. Lomont then searched for a constant optimal even after one and two Newton iterations and found 0x5F375A86, which is more accurate than the original at every iteration stage.&lt;&#x2F;p&gt;
&lt;p&gt;Subsequent additions by hardware manufacturers have made this algorithm redundant for the most part. For example, on x86, Intel introduced the SSE instruction rsqrtss in 1999. In a 2009 benchmark on the Intel Core 2, this instruction took 0.85ns per float compared to 3.54ns for the fast inverse square root algorithm, and had less error.&lt;&#x2F;p&gt;
</content>
        
    </entry>
</feed>
